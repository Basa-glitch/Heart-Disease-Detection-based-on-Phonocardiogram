{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgXn7lsaOUaV"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.signal import spectrogram\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtfK2-55O-uo"
      },
      "outputs": [],
      "source": [
        "!unzip Data2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgT1mvQbO_zW"
      },
      "outputs": [],
      "source": [
        "# Dataset files should be located at the same directory with this notebook.\n",
        "\n",
        "dataset = [{'file': file, 'class': file.split('/')[1]}\n",
        "           for file in glob.glob(\"Data/**/*.wav\")]\n",
        "\n",
        "dataframe = pd.DataFrame.from_dict(dataset)\n",
        "dataframe['data'] = dataframe['file'].apply(lambda amplitude: wavfile.read(amplitude)[1])\n",
        "\n",
        "print(\"Dataset size is\", dataframe['data'].size, \"elements.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFNpsz49PeBX"
      },
      "outputs": [],
      "source": [
        "# Feature extraction using librosa (MFCCs)\n",
        "def extract_features(file):\n",
        "    y, sr = librosa.load(file, sr=None)  # Load the audio file\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # Extract MFCC features\n",
        "    return np.mean(mfcc.T, axis=0)  # Return the mean of the MFCC features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44jfcKy4PiGy"
      },
      "outputs": [],
      "source": [
        "# Apply feature extraction to the dataset\n",
        "dataframe['features'] = dataframe['file'].apply(extract_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJwZcIbJPjRy"
      },
      "outputs": [],
      "source": [
        "# Visualizing example features (optional)\n",
        "normal = dataframe[dataframe['class'] == 'Normal_2'].sample(1)\n",
        "murmur = dataframe[dataframe['class'] == 'Murmur_2'].sample(1)\n",
        "extrastole = dataframe[dataframe['class'] == 'Extrastole_2'].sample(1)\n",
        "\n",
        "# Visualization function remains the same (adapted to MFCC features)\n",
        "def visualize(data, typename, color, sampling_frequency=48000):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.title(typename + ' MFCC features plot')\n",
        "    plt.plot(data.values[0], c=color)\n",
        "    plt.ylabel('MFCC Coefficients')\n",
        "    plt.xlabel('Time')\n",
        "\n",
        "visualize(normal['features'], \"Normal_2\", 'g')\n",
        "visualize(murmur['features'], \"Murmur_2\", 'b')\n",
        "visualize(extrastole['features'], \"Extrastole_2\", 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4l_-JfsPkNN"
      },
      "outputs": [],
      "source": [
        "# Prepare the dataset for machine learning\n",
        "X = np.stack(dataframe['features'].values, axis=0)  # Features (MFCCs)\n",
        "y = dataframe['class'].values  # Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gedlm-DPmSe"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gUSPZ9yT-Cz"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Instantiate the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data and transform it\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply the scaler to the test data\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6U6fbaoPuxj",
        "outputId": "75b46126-a36e-41aa-f875-7b5bc3066c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "Best KNN accuracy: 0.9420289855072463\n",
            "Best Validation Accuracy from GridSearchCV: 0.9290322580645162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_neighbors': np.arange(1, 20),  # Searching for best k between 1 and 10\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'],  # Trying different distance metrics\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "# Instantiate the KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Instantiate GridSearchCV with the KNeighborsClassifier and parameter grid\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')  # fold cross-validation\n",
        "\n",
        "# Fit GridSearchCV on the scaled training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(\"Best parameters found:\", grid_search.best_params_)\n",
        "\n",
        "# Use the best estimator to make predictions\n",
        "best_knn = grid_search.best_estimator_\n",
        "knn_predictions = best_knn.predict(X_test_scaled)\n",
        "\n",
        "# Print the accuracy of the best model\n",
        "print(\"Best KNN accuracy:\", accuracy_score(y_test, knn_predictions))\n",
        "\n",
        "# Print the best validation accuracy during GridSearchCV\n",
        "print(\"Best Validation Accuracy from GridSearchCV:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZVs0AQrHCMv"
      },
      "source": [
        "# Methods for Validation Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9vh7VzBFOED"
      },
      "source": [
        "**1. Using 'GridSearchCV' Cross-Validation accuracy**\n",
        "\n",
        "mean_test_score: This represents the average validation accuracy across all cross-validation folds.\n",
        "\n",
        "std_test_score: This is the standard deviation of the validation accuracy across the folds, giving you a sense of how much variability there was in the validation performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuGBTx1aBXYf",
        "outputId": "2c847b91-554b-4216-fe6d-d1df98a6417f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "Cross-validation results:\n",
            "                                                params  mean_test_score  \\\n",
            "0    {'metric': 'euclidean', 'n_neighbors': 1, 'wei...         0.911290   \n",
            "1    {'metric': 'euclidean', 'n_neighbors': 1, 'wei...         0.911290   \n",
            "2    {'metric': 'euclidean', 'n_neighbors': 2, 'wei...         0.770968   \n",
            "3    {'metric': 'euclidean', 'n_neighbors': 2, 'wei...         0.911290   \n",
            "4    {'metric': 'euclidean', 'n_neighbors': 3, 'wei...         0.683871   \n",
            "..                                                 ...              ...   \n",
            "109  {'metric': 'minkowski', 'n_neighbors': 17, 'we...         0.924194   \n",
            "110  {'metric': 'minkowski', 'n_neighbors': 18, 'we...         0.712903   \n",
            "111  {'metric': 'minkowski', 'n_neighbors': 18, 'we...         0.925806   \n",
            "112  {'metric': 'minkowski', 'n_neighbors': 19, 'we...         0.716129   \n",
            "113  {'metric': 'minkowski', 'n_neighbors': 19, 'we...         0.927419   \n",
            "\n",
            "     std_test_score  \n",
            "0          0.023093  \n",
            "1          0.023093  \n",
            "2          0.035921  \n",
            "3          0.023093  \n",
            "4          0.045734  \n",
            "..              ...  \n",
            "109        0.027983  \n",
            "110        0.020145  \n",
            "111        0.024140  \n",
            "112        0.021878  \n",
            "113        0.026256  \n",
            "\n",
            "[114 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Perform the grid search\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best parameters found:\", grid_search.best_params_)\n",
        "\n",
        "# Show the validation accuracy for each set of parameters\n",
        "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
        "print(\"Cross-validation results:\")\n",
        "print(cv_results[['params', 'mean_test_score', 'std_test_score']])\n",
        "\n",
        "# The mean_test_score column gives you the mean validation accuracy across all folds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIkatoD-FvMR"
      },
      "source": [
        "**2. Manual Validation Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3k2aRSjFV2k",
        "outputId": "d201313f-d2bd-446a-fd28-04e9761ceff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.7391304347826086\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Train the model on the training subset\n",
        "knn = KNeighborsClassifier(n_neighbors=20)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Calculate validation accuracy\n",
        "val_predictions = knn.predict(X_test)\n",
        "val_accuracy = accuracy_score(y_test, val_predictions)\n",
        "print(\"Validation accuracy:\", val_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKsmbpFeG5rb"
      },
      "source": [
        "**3. GridSearchCV with Validation Accuracy Display**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgl0wUBYG1Ds",
        "outputId": "7f3f9d9d-61ca-4321-dcd1-51aaabe0e17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation/Test accuracy of the best model: 0.9420289855072463\n"
          ]
        }
      ],
      "source": [
        "# Best model from GridSearchCV\n",
        "best_knn = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the validation/test set\n",
        "knn_val_predictions = best_knn.predict(X_test_scaled)\n",
        "\n",
        "# Calculate and display validation accuracy\n",
        "val_accuracy = accuracy_score(y_test, knn_val_predictions)\n",
        "print(\"Validation/Test accuracy of the best model:\", val_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22rfArThMlbF",
        "outputId": "913b435b-1d0b-4468-ac10-f8a1ae4aeb78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision of the best KNN model: 0.945814212750512\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Predict on the test set using the best KNN model\n",
        "knn_predictions = best_knn.predict(X_test_scaled)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, knn_predictions, average='weighted')\n",
        "\n",
        "# Display precision\n",
        "print(\"Precision of the best KNN model:\", precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKEdxC64PMe5",
        "outputId": "001e87bc-9a7d-4108-82ba-cda7dc01a434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Precision of the best KNN model: 0.945814212750512\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Assuming you already have the best model from GridSearchCV\n",
        "# If you haven't trained it, you can refer to the code earlier for training it\n",
        "best_knn = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the validation/test set\n",
        "val_predictions = best_knn.predict(X_test_scaled)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, val_predictions, average='weighted')\n",
        "\n",
        "# Display validation precision\n",
        "print(\"Validation Precision of the best KNN model:\", precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrQQelUkTs4X"
      },
      "source": [
        "'macro': For unweighted mean of the precision.\n",
        "\n",
        "'micro': For global precision considering all instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHuKT9PKTnfd",
        "outputId": "a1f5e49a-81d9-42fc-b603-8c9174ec87ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Precision (weighted): 0.945814212750512\n",
            "Validation Precision (macro): 0.9153249850924269\n",
            "Validation Precision (micro): 0.9420289855072463\n"
          ]
        }
      ],
      "source": [
        "# Calculate weighted and macro precision\n",
        "precision_weighted = precision_score(y_test, val_predictions, average='weighted')\n",
        "precision_macro = precision_score(y_test, val_predictions, average='macro')\n",
        "precision_micro = precision_score(y_test, val_predictions, average='micro')\n",
        "\n",
        "# Display both precision values\n",
        "print(\"Validation Precision (weighted):\", precision_weighted)\n",
        "print(\"Validation Precision (macro):\", precision_macro)\n",
        "print(\"Validation Precision (micro):\", precision_micro)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "w3RMLN2hT1L0",
        "outputId": "7e279d08-7df7-4b4d-9c6f-ce3db915fa85"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_92f268fb-be6a-4c58-b679-be07bd437948\", \"best_knn_model.pkl\", 115846)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import joblib\n",
        "from google.colab import files  # Only needed if you're using Google Colab\n",
        "\n",
        "# Save the trained KNN model to a file\n",
        "joblib.dump(best_knn, 'best_knn_model.joblib')\n",
        "\n",
        "# Optional: Download the saved model if you are using Google Colab\n",
        "files.download('best_knn_model.joblib')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}